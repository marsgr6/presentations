{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solving a System of Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "We will deal with the case of determining the values $x_1, x_2, \\dots, x_n$ that simultaneously satisfy a set of linear equations of the form\n",
    "\n",
    "$$\n",
    "a_{11}x_1 + a_{12}x_2 + \\dots, a_{1n}x_n = b_1\\\\\n",
    "a_{21}x_1 + a_{22}x_2 + ....., a_{2n}x_n = b_2 \\\\\n",
    "a_{n1}x_1 + a_{n2}x_2 + ....., a_{nn}x_n = b_n\n",
    "$$\n",
    "\n",
    "For small numbers of equations $(n 3)$, linear equations can be solved readily by simple techniques.\n",
    "\n",
    "However, for four or more equations, solutions become arduous and computers must be utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The system of equations introduced above can be represented in a compact form\n",
    "\n",
    "$$\n",
    "[A]X = B\n",
    "$$\n",
    "\n",
    "where [A] is an $n \\times n$ matrix of coefficients\n",
    "\n",
    "$$\n",
    "A=\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\dots & a_{1n}\\\\\n",
    "a_{21} & a_{22} & \\dots & a_{2n}\\\\\n",
    "a_{n1} & a_{n2} & \\dots & a_{nn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$B$ is the $n \\times 1$ column vector of constants, and $X$ is the $n \\times 1$ column vector of unknowns:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/bxm.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example \n",
    "\n",
    "Using Kirchhoffs law, the currents $i_1,\\ i_2,\\ i_3$, and $i_4$ can be determined by solving the following system of four equations:\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/kirchhoffs_eq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical methods for solving a system of linear algebraic equations\n",
    "\n",
    "- Two types of numerical methods, **direct** and **iterative**, are used for solving systems of linear algebraic equations. \n",
    "\n",
    "- In **direct** methods, the solution is calculated by performing arithmetic operations with the equations. \n",
    "\n",
    "- In **iterative methods**, an initial approximate solution is assumed and then used in an iterative process for obtaining successively more accurate solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Direct methods\n",
    "\n",
    "- In direct methods, the system of equations that is initially given in the general form, is manipulated to an equivalent system of equations that can be easily solved. \n",
    "\n",
    "- Three systems of equations that can be easily solved are the \n",
    "  - upper triangular, \n",
    "  - lower triangular, and \n",
    "  - diagonal forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The system in the upper triangular form has all zero coefficients below the diagonal and is solved by a procedure called back substitution.\n",
    "\n",
    "- It starts with the last equation, which is solved for $x_n$. The value of $x_n$ is then substituted in the next-to-the-last equation, which is solved for $x_{n−1}$. \n",
    "\n",
    "- The process continues in the same manner all the way up to the first equation.\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The system in the lower triangular form has zero coefficients above the diagonal and is solved in the same way as the upper triangular form but in an opposite order. \n",
    "\n",
    "- The procedure is called forward substitution. It starts with the first equation, which is solved for $x_1$. \n",
    "\n",
    "- The value of $x_1$ is then substituted in the second equation, which is solved for $x_2$. The process continues in the same manner all the way down to the last equation.\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- A system in diagonal form has nonzero coefficients along the diagonal and zeros everywhere else. \n",
    "\n",
    "- Obviously, a system in this form can be easily solved.\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq3.png)\n",
    "\n",
    "- Two direct methods for solving systems of equations **Naïve Gauss elimination**, and **LU decomposition** are described in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Gauss elimination method\n",
    "\n",
    "- The technique consists of two phases: **elimination of unknowns** and **solution through back substitution**.\n",
    "\n",
    "- Although these techniques are ideally suited for implementation on computers, some modifications will be required to obtain a reliable algorithm.\n",
    "\n",
    "- In particular, the computer program must avoid division by zero.\n",
    "\n",
    "- The method is called naive Gauss elimination because it does not avoid this problem.\n",
    "\n",
    "- To perform row reduction on a matrix, one uses a sequence of elementary row operations to modify the matrix until the lower left-hand corner of the matrix is filled with zeros, as much as possible. There are three types of elementary row operations:\n",
    "\n",
    "  - Swapping two rows,\n",
    "  - Multiplying a row by a nonzero number,\n",
    "  - Adding a multiple of one row to another row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward elimination of unknowns\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward elimination of unknowns\n",
    "\n",
    "- Row one is called the pivot equation and $a_{11}$ is called the pivot coefficient or element. \n",
    "\n",
    "- The process of multiplying the first row by $a_{21}/a_{11}$ is equivalent to dividing it by $a_{11}$ and multiplying it by $a_{21}$. \n",
    "\n",
    "- The division operation is referred to as normalization. This distinction is made, because a zero pivot element can interfere with normalization by causing a division by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward elimination of unknowns\n",
    "\n",
    "- Repeating the step above to eliminate the second unknown from row 3 through n in the last set of equations. To do this multiply the second row by $a'_{32}/a'_{22}$ and subtract the result from the third equation. Perform a similar elimination for the remaining equations to yield:\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq5.png)\n",
    "\n",
    "where the double prime indicates that the elements have been modified twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward elimination of unknowns\n",
    "\n",
    "- The procedure can be continued using the remaining pivot equations. \n",
    "\n",
    "- The final manipulation in the sequence is to use the $(n1)^{th}$ equation to eliminate the $x_{n1}$ term from the nth equation. \n",
    "\n",
    "- At this point, the system will have been transformed to an upper triangular system:\n",
    "  \n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back substitution\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LU decomposition method\n",
    "\n",
    "- Gauss elimination is designed to solve systems of linear algebraic equations\n",
    "\n",
    "$$[A]X=B$$\n",
    "\n",
    "- What about solving equations with the same coefficients $[A]$, but with different right-hand-side constants $B$.\n",
    "\n",
    "- LU decomposition methods separate the time-consuming elimination of the matrix $[A]$ from the manipulations of the right-hand side B.\n",
    "\n",
    "- Thus, once $[A]$ has been decomposed, multiple right-hand-side vectors can be evaluated in an efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LU decomposition method\n",
    "\n",
    "- A two-step strategy  for obtaining solutions can be based explained as follow\n",
    "- **LU decomposition step:** $[A]$ is factored or decomposed into lower $[L]$ and upper $[U]$ triangular matrices.\n",
    "- **Substitution step:** $[L]$ and $[U]$ are used to determine a solution $X$ for a right-hand side $B$. This step itself consists of two steps. First, an intermediate vector $D$ is generated by forward substitution. Then, the result is substituted back to solve for $X$ by back substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LU decomposition method\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LU decomposition method\n",
    "\n",
    "- The forward-substitution step can be represented concisely as\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq8.png)\n",
    "\n",
    "– The back-substitution step can be represented concisely as\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/leq9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iterative methods\n",
    "\n",
    "- Iterative or approximate methods provide an alternative to the elimination methods described previously. \n",
    "- Such approaches are similar to the techniques used to obtain the roots of a single equation (fixed point iteration). \n",
    "- Those approaches consisted of guessing a value and then using a systematic method to obtain a refined estimate of the root. \n",
    "- Two iterative methods will be presented: **Gauss-Seidel** and **Jacobi**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Seidel method\n",
    "\n",
    "The Gauss–Seidel method is an iterative technique for solving a square system of $n$ linear equations with unknown $x$:\n",
    "\n",
    "$$A\\mathbf {x} =\\mathbf {b}$$\n",
    "\n",
    "It is defined by the iteration\n",
    "$$L_{*}\\mathbf {x} ^{(k+1)}=\\mathbf {b} -U\\mathbf {x} ^{(k)}$$\n",
    "\n",
    "where \n",
    "$\\mathbf {x} ^{(k)}$ is the $k$ approximation or iteration of \n",
    "$ \\mathbf {x} ,\\,\\mathbf {x} ^{(k+1)}$ is the next or $k + 1$ iteration of \n",
    "$\\mathbf {x}$, and the matrix $A$ is decomposed into a lower triangular component \n",
    "$L_{*}$, and a strictly upper triangular component U: \n",
    "$A=L_{*}+U.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In more detail, write out $A$, $\\mathbf{x}$ and $\\mathbf{b}$ in their components:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/98608e9e95d5acad149813eca75c8108acec308a)\n",
    "\n",
    "Then the decomposition of $A$ into its lower triangular component and its strictly upper triangular component is given by:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/7ae078c14c6e5b484013b66aa4054fc5f371a6f5)\n",
    "\n",
    "The system of linear equations may be rewritten as:\n",
    "$L_{*}\\mathbf {x} =\\mathbf {b} -U\\mathbf {x}$.\n",
    "\n",
    "The Gauss–Seidel method now solves the left hand side of this expression for $x$, using previous value for $x$ on the right hand side. Analytically, this may be written as:\n",
    "\n",
    "$$\\mathbf {x} ^{(k+1)}=L_{*}^{-1}(\\mathbf {b} -U\\mathbf {x} ^{(k)}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Element wise formula for the Gauss–Seidel method\n",
    "\n",
    "- The elements of $x^{(k+1)}$ can be computed sequentially using forward substitution:\n",
    "$${\\displaystyle x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j=1}^{i-1}a_{ij}x_{j}^{(k+1)}-\\sum _{j=i+1}^{n}a_{ij}x_{j}^{(k)}\\right),\\quad i=1,2,\\dots ,n.}$$\n",
    "\n",
    "- The procedure is generally continued until the changes made by an iteration are below some tolerance, such as a sufficiently small residual.\n",
    "\n",
    "- The computation of $x^{(k+1)}$ uses the elements of $x^{(k+1)}$ that have already been computed, and only the elements of $x^{(k)}$ that have not been computed in the $k+1$ iteration. \n",
    "\n",
    "- Convergence can be checked as:\n",
    "$$ \\epsilon_{a,i} = \\frac{|x_i^{(k)}-x_i^{(k-1)}|}\n",
    "{|x_i^{(k)}|} < \\epsilon_s$$\n",
    "\n",
    "See: https://en.wikipedia.org/wiki/Gauss–Seidel_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algorithm\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/gauss_seidel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jacobi method\n",
    "\n",
    "Let\n",
    "$$A\\mathbf {x} =\\mathbf {b}$$\n",
    "be a square system of n linear equations, where:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/98608e9e95d5acad149813eca75c8108acec308a)\n",
    "\n",
    "Then $A$ can be decomposed into a diagonal component $D$, a lower triangular part $L$ and an upper triangular part $U$:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/bcf5d9cdfca7999d403b882555a57ea2669bb12b)\n",
    "\n",
    "The solution is then obtained iteratively via\n",
    "${\\displaystyle \\mathbf {x} ^{(k+1)}=D^{-1}(\\mathbf {b} -(L+U)\\mathbf {x} ^{(k)}),}$\n",
    "where \n",
    "$\\mathbf {x} ^{(k)}$ is the $k$ approximation or iteration of \n",
    "$\\mathbf {x}$  and \n",
    "$\\mathbf {x} ^{(k+1)}$ is the next or $k + 1$ iteration of \n",
    "$\\mathbf {x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Element wise formula for the Jacobi method\n",
    "\n",
    "The element-based formula is:\n",
    "$$x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j\\neq i}a_{ij}x_{j}^{(k)}\\right),\\quad i=1,2,\\ldots ,n.$$\n",
    "The computation of \n",
    "${\\displaystyle x_{i}^{(k+1)}}$ requires each element in $x^{(k)}$ except itself. Unlike the Gauss–Seidel method, we can't overwrite \n",
    "${\\displaystyle x_{i}^{(k)}}$ with \n",
    "${\\displaystyle x_{i}^{(k+1)}}$, as that value will be needed by the rest of the computation. The minimum amount of storage is two vectors of size $n$.\n",
    "\n",
    "Convergence can be checked as:\n",
    "$$ \\epsilon_{a,i} = \\frac{|x_i^{(k)}-x_i^{(k-1)}|}\n",
    "{|x_i^{(k)}|} < \\epsilon_s$$\n",
    "\n",
    "See: https://en.wikipedia.org/wiki/Jacobi_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algorithm\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/jacobi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Element wise formula: Jacobi\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/jacobi_ew.png)\n",
    "\n",
    "  - The element-based formula is:\n",
    "$$x_{i}^{(k)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j\\neq i}a_{ij}x_{j}^{(k-1)}\\right),\\quad i=1,2,\\ldots ,n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Element wise formula: Gauss-Seidel\n",
    "\n",
    "![](https://raw.githubusercontent.com/marsgr6/r-scripts/master/imgs/gauss_seidel_ew.png)\n",
    "\n",
    "- The elements of $x^{(k)}$ can be computed sequentially using forward substitution:\n",
    "$${\\displaystyle x_{i}^{(k)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j=1}^{i-1}a_{ij}x_{j}^{(k)}-\\sum _{j=i+1}^{n}a_{ij}x_{j}^{(k-1)}\\right),\\quad i=1,2,\\dots ,n.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implement the element wise algorithm for:\n",
    "\n",
    "- Jacobi method to solve the following system:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/d99d9203a7aa825aeff53f7e0cbe0328ac9d56d2)\n",
    "\n",
    "- Gauss-Seidel method to solve the following system:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/b27b11eea7dcf426694f15f5ce6d2988bcc1328f)\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/7a365bbe27115afa832f96e50a7fd8dbf5bf5b18)\n",
    "\n",
    "Use same values for $x^{(0)}=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \n",
    "\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sources and resoruces:\n",
    "\n",
    "- http://www.math-cs.gordon.edu/courses/ma342/\n",
    "\n",
    "- http://www.math-cs.gordon.edu/courses/ma342/handouts/gauss.pdf\n",
    "\n",
    "- https://algowiki-project.org/en/Forward_substitution\n",
    "\n",
    "- http://people.duke.edu/~ccc14/sta-663-2016/08_LinearAlgebra2.html\n",
    "\n",
    "- https://www.mathworks.com/help/matlab/ref/mldivide.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}